---
title: "Data Processing"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(tidyverse)
library(plotly)
library(janitor)
library(readr)
library(statar)
options(readr.show_col_types = FALSE)
```

# Air Quality datasets

## Data Cleaning - Neighborhood-level 

This dataset has neighborhood-level air quality data. It has 6300 rows and 16 columns.
<<<<<<< HEAD

This code chunk fixes the projection used to map the neighborhood-level air quality dataset, and calculates a point as the center of the neighborhood. This will be used for maps later on.

=======
>>>>>>> 808e185933410e4efeb7eac853ef1f791859c7b6
```{r eval=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(sf)
library(sfheaders)

df_air = read_csv(here::here("data/raw_data/air_quality.csv")) %>%
  janitor::clean_names() %>%
  select(-message) %>%
  mutate(id = as.character(geo_join_id)) %>%
  filter(geo_type_name == "UHF42")

#shapefiles aren't in the repository due to their size
zip_shapes = read_sf(dsn = here::here("raw_shapes/"), 
                     layer = 'tl_2019_us_zcta510') %>% 
  rename(zip = ZCTA5CE10)

air_shapes = read_sf(dsn = "raw_shapes/", layer = "UHF42") %>%
  filter(id != "0") %>%
  st_transform(crs= st_crs(zip_shapes)) %>%
  rename(geo_join_id = id) %>%
  mutate(geo_join_id = as.numeric(geo_join_id))

df_air = df_air %>%
  left_join(air_shapes) %>%
   mutate(x_center = map_dbl(geometry, ~st_point_on_surface(.x)[[1]]),
         y_center = map_dbl(geometry, ~st_point_on_surface(.x)[[2]]),
         intplon10 = x_center, intplat10 = y_center) #I do this so that the 
        #zip_code shape files and UHF air quality shapefiles have the same 
        #variable names for the point in the center of polygons
        #Otherwise, code done with zip_code shapefiles would need to be
        #edited to account for these new variable names

df_air %>%
  select(-geometry) %>% 
  write_csv(here::here("data/cleaned_data/uhf_airquality.csv"))
```

## Mapping neighborhoods to daily sensors

We want to do regression at the neighborhood level, but our daily air quality data only gave us the specific location where the pollutant was measured. This code mapped measurement sensors from our daily air quality data to neighborhoods.

```{r eval=FALSE, message=FALSE, warning=FALSE}
df_air = read_csv(here::here("data/cleaned_data/uhf_airquality.csv"))

zip_shapes = read_sf(dsn = here::here("raw_shapes/"), 
                     layer = 'tl_2019_us_zcta510') %>% 
  rename(zip = ZCTA5CE10)

air_shapes = read_sf(dsn = here::here("raw_shapes/"), layer = "UHF42") %>%
  filter(id != "0") %>%
  st_transform(crs= st_crs(zip_shapes)) %>%
  rename(geo_join_id = id) %>%
  mutate(geo_join_id = as.numeric(geo_join_id))

df_air = df_air %>%
  left_join(air_shapes) %>%
   mutate(x_center = map_dbl(geometry, ~st_point_on_surface(.x)[[1]]),
         y_center = map_dbl(geometry, ~st_point_on_surface(.x)[[2]]),
         intplon10 = x_center, intplat10 = y_center)

daily_air = read_csv(here::here("data/cleaned_data/alt_air_data.csv"))

daily_air = daily_air %>%
  st_as_sf(coords = c("x", "y"), crs = st_crs(zip_shapes))

geo_joins_sites = st_join(daily_air, air_shapes, join = st_within)  %>%
  select(zip_code, site_name, geo_join_id, pollutant) %>%
  group_by(zip_code, site_name, pollutant) %>%
  summarize(geo_join_id = mean(geo_join_id))

geo_join_neighborhoods = df_air %>%
  group_by(geo_place_name) %>%
  summarize(geo_join_id = mean(geo_join_id))

left_join(geo_joins_sites, geo_join_neighborhoods) %>%
  select(zip_code, site_name, pollutant, geo_place_name) %>%
  write_csv(here::here("data/cleaned_data/pollutant_per_neighborhood.csv"))
```

## Daily Air Quality Data - Neighborhood-level

We used the dataset just created to summarize pollutant measurements at the neighborhood level. After doing this, we had daily data on pollutants at the neighborhood level, which allowed for regression.

```{r eval=FALSE, message=FALSE, warning=FALSE}
#neighborhoods on interest:

neighborhoods = c("Washington Heights", "Union Square - Lower East Side",
                  "Willowbrook", "Hunts Point - Mott Haven", "Fresh Meadows")

store_data = vector("list", length = 5)

for (i in 1:length(neighborhoods)) {
  
  n = neighborhoods[i]
  
  n_zips = sites_nghbors %>%
  filter(geo_place_name == n) %>%
  pull(zip_code)
  
  daily_data = daily_air %>%
    filter(zip_code %in% n_zips) %>%
    group_by(date, pollutant) %>%
    summarize(mean_value = mean(value)) %>%
    mutate(neighborhood = n)
  
  store_data[[i]] = daily_data
  
}

daily_neighborhood_data = bind_rows(store_data[[1]], store_data[[2]]) %>%
  bind_rows(store_data[[3]]) %>%
  bind_rows(store_data[[4]]) %>%
  bind_rows(store_data[[5]]) %>%
  mutate(date = as.Date(date, format = "%m/%d/%Y"))
```





# Disease datasets

## Merging hospitalization/emergency department data 

Since we pulled disease/illness related data from two different sources, the code below reflects the cleaning of individual datasets and merging of the two. We now have data for asthma, respiratory diseases, influenza-like/pneumonia ER visits and admissions, and all other ER admissions by zip code and date.

```{r, message = FALSE}
# Load dataset with respiratory and asthma counts (missing some zipcodes)

dis_asth_df = read_csv(here::here("data/raw_data/joined_respiratory.csv"),
                       col_types = cols(
                          `date` = col_date(format = '%m/%d/%y'))) |> 
  rename(zip_code = zip) |> 
  filter(zip_code != 88888 & zip_code != "Citwide" & age_group == "All age groups") |> 
  mutate(year = as.numeric(format(date, format = "%Y")),
         month = month.name[as.numeric(format(date, format = "%m"))],
         day = as.numeric(format(date, format = "%d")),
         zip_code = as.numeric(zip_code)) |>
  select(year, month, day, zip_code, count_resp, count_asth) 

# Load dataset with pneumonia data

dis_pneu_df = read_csv(here::here("data/raw_data/disease_hospital_admin.csv"),
                       col_types = cols(
                                     `date` = col_date(format = "%m/%d/%Y"),
                                     `total_ed_visits` = col_integer(),
                                     `ili_pne_visits` = col_integer(),
                                     `ili_pne_admissions` = col_integer())) |> 
  separate(date, into=c("year", "month", "day")) |> 
  mutate(day = as.numeric(day),
         month = month.name[as.numeric(month)],
         year = as.numeric(year)) |> 
  rename(zip_code = mod_zcta) |> 
  select(year, month, day, zip_code, total_ed_visits, ili_pne_visits, ili_pne_admissions)

# Merge two disease datasets

all_dis_df =
  full_join(dis_asth_df, dis_pneu_df, by = c("zip_code", "year", 'month', 'day'))
```

## Merging hospitalization/emergency department data with zip code data 

Since our above merged dataset only contains zip code-level data, we added neighborhood and borough information using a zip code dataset containing that information. Note that after exploring that outputed data, some zip codes needed manual inputs for neighborhood and borough information. The code below reflects this process. 

```{r, message = FALSE}
#loading zip code data
zip_shapes <- read_csv(here::here('data/cleaned_shapes/nyc_zip_codes.csv')) %>%
  clean_names()

# merging disease with zip code data to add neigh & borough data

all_dis_df <- left_join(all_dis_df, zip_shapes, by = 'zip_code') %>%
  mutate(
    #these zip codes needed manual inputs
    #bc not in zip_shapes file
    neighborhood = case_when(
      zip_code == '10069' ~ 'Upper West Side',
      zip_code == '11109' ~ 'Northwest Queens',
      zip_code == '10282' ~ 'Lower Manhattan',
      zip_code == '10271' ~ 'Lower Manhattan',
      zip_code == '10278' ~ 'Lower Manhattan',
      zip_code == '10279' ~ 'Lower Manhattan',
      #zip_code == '11003' ~ 10000 (deal w these)
      #zip_code == '11040'
      TRUE ~ neighborhood),
    
    borough = case_when(
      zip_code == '10069' ~ 'Manhattan',
      zip_code == '11109' ~ 'Queens',
      zip_code == '10282' ~ 'Manhattan',
      zip_code == '10271' ~ 'Manhattan',
      zip_code == '10278' ~ 'Manhattan',
      zip_code == '10279' ~ 'Manhattan',
      TRUE ~ borough)) %>%
  
  #removing these zip codes bc
  #not apart of the 5 boroughs
  filter(!(zip_code == '10000'),
         !(zip_code == '11003'),
         !(zip_code == '11040'))
```


## Disease Dataset - EDA

```{r, message = FALSE}
disease_eda <- all_dis_df %>%
  pivot_longer(cols = 'count_resp':'ili_pne_admissions',
               names_to = 'illness_counts',
               values_to = 'count') %>%
  mutate(month_num = match(month, month.name),
         date = as.Date(paste(year, month_num, day, sep = '-'),
                        format = '%Y-%m-%d'),
         
         illness_counts = case_when(
           illness_counts == 'total_ed_visits' ~ 'ED visits (overall)',
           illness_counts == 'ili_pne_visits' ~ 'Pneumonia (ER visits)',
           illness_counts == 'ili_pne_admissions' ~ 'Pneumonia (ER admissions)',
           illness_counts == 'count_resp' ~ 'Respiratory diseases',
           illness_counts == 'count_asth' ~ 'Asthma'))
```


## Disease Count Dataset - Neighborhood-level

Using the dataset just created, we summarized illness counts at the neighborhood level. We focused on 5 specific neighborhoods, each in a different borough. This provided us with daily data on illness counts for the 5 boroughs/neighborhoods, which allowed for time-series EDA, and the joining of disease and air quality data for regression.

```{r, message = FALSE}
#neighborhoods of interest
neighborhoods = c("Inwood and Washington Heights", "Lower East Side",
                  "Mid-Island", "Hunts Point and Mott Haven", "Central Queens")



daily_disease_neigh = disease_eda %>%
  filter(neighborhood %in% neighborhoods) %>%
  group_by(date, borough, neighborhood, illness_counts) %>% 
  summarize(total_counts = sum(count, na.remove = T)) %>%
  #need neighborhood names to match
  mutate(neighborhood = case_when( 
    neighborhood == "Inwood and Washington Heights" ~ "Washington Heights",
    neighborhood == "Lower East Side"  ~  "Union Square - Lower East Side",
    neighborhood ==  "Mid-Island" ~ "Willowbrook",
    neighborhood == "Hunts Point and Mott Haven" ~ 
      "Hunts Point - Mott Haven",
    neighborhood == "Central Queens" ~"Fresh Meadows"
  ),
  date = as.Date(date, format = '%Y-%m-%d'))
```








# Merging Air Quality and Disease Datasets

Now, having daily disease data and daily air quality data at the neighborhood level allows for a smooth merging of datasets. The final merged dataset contains daily information on illness counts and pollutants by neighborhoods. We also added a season variable to aid our regression analysis.

```{r, message = FALSE}
#altering format
daily_disease_neigh = daily_disease_neigh %>%
  pivot_wider(names_from = illness_counts, values_from = total_counts)

#loading fixed air quality data
air_neighb <- read_csv(here::here('data/cleaned_data/air_neighborhood.csv'))

#altering format
air_neighb = air_neighb %>%
  pivot_wider(names_from = pollutant, values_from = mean_value)

#merging air & disease
disease_air <- full_join(daily_disease_neigh, air_neighb, by = c('date', "neighborhood")) %>%
  filter(date >= '2020-03-01' & date < '2022-12-01') %>%
  mutate(year = as.factor(format(date, format = '%Y')),
         month = month.name[as.numeric(format(date, format = "%m"))],
         day = as.numeric(format(date, format = "%d")),
         #adding seasons
         season = case_when(
           month %in% c('June', 'July', 'August') ~ 'Summer',
           month %in% c('September', 'October', 'November') ~ 'Fall',
           month %in% c('December', 'January', 'February') ~ 'Winter',
           month %in% c('March', 'April', 'May') ~ 'Spring'))
```









# Regression Analysis Data

We altered the final merged dataset to aid our regression. Since the Union Square - Lower East Side neighborhood only contained information for the PM2.5 pollutant, we decided to remove the neighborhood from the dataset. Additionally, our EDA revealed that Asthma and Respiratory diseases had very few counts of admittance, which would result in them not being great responses in models. Thus, they were both removed. Furthermore, 


```{r, message = FALSE}
new_disease_air = disease_air %>%
  filter(neighborhood != "Union Square - Lower East Side") %>%
  select(-NO2, -Asthma, -`Respiratory diseases`) %>%
  arrange(date) %>%
  group_by(neighborhood) %>%
  mutate(lagged_ozone = tlag(Ozone, 1, time = date),
         lagged_pm = tlag(PM2.5, 1, time = date)) %>%
  rename( total_ed_visits = `ED visits (overall)`,
          ili_pne_visits = `Pneumonia (ER visits)`)
```

